#!/usr/bin/env python3
"""
Comprehensive Test Suite for Database Integration Module
Tests both real and simulated database operations
"""

import os
import sys
import json
import time
import logging
from typing import Dict, Any, List

# Add the agent directory to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from database_integration import DatabaseIntegration, get_database_integration

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DatabaseIntegrationTester:
    """Comprehensive tester for database integration"""
    
    def __init__(self):
        self.db = None
        self.test_results = []
        self.start_time = time.time()
        
    def run_all_tests(self) -> Dict[str, Any]:
        """Run all database integration tests"""
        logger.info("=== Starting Database Integration Test Suite ===")
        
        try:
            # Initialize database integration
            self.db = get_database_integration()
            
            # Run test categories
            self._test_initialization()
            self._test_connection_string()
            self._test_connection()
            self._test_schema_discovery()
            self._test_sql_generation()
            self._test_query_execution()
            self._test_performance_analysis()
            self._test_error_handling()
            self._test_cleanup()
            
            # Generate summary
            return self._generate_test_summary()
            
        except Exception as e:
            logger.error(f"Test suite failed: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'message': 'Test suite execution failed'
            }
    
    def _test_initialization(self):
        """Test database integration initialization"""
        logger.info("Testing database integration initialization...")
        
        try:
            # Test singleton pattern
            db1 = get_database_integration()
            db2 = get_database_integration()
            
            assert db1 is db2, "Database integration should be singleton"
            
            # Test basic attributes
            assert hasattr(self.db, 'connection_string'), "Should have connection_string attribute"
            assert hasattr(self.db, 'schema_cache'), "Should have schema_cache attribute"
            assert hasattr(self.db, 'query_cache'), "Should have query_cache attribute"
            
            self._add_test_result("initialization", True, "Database integration initialized successfully")
            
        except Exception as e:
            self._add_test_result("initialization", False, f"Initialization failed: {str(e)}")
    
    def _test_connection_string(self):
        """Test connection string generation"""
        logger.info("Testing connection string generation...")
        
        try:
            # Test getting connection string
            conn_str = self.db.get_connection_string()
            
            assert conn_str is not None, "Connection string should not be None"
            assert conn_str.startswith('postgresql://'), "Should be PostgreSQL connection string"
            assert '@' in conn_str, "Should contain authentication info"
            assert ':5432/' in conn_str, "Should contain port and database"
            
            # Test with environment variable
            original_env = os.environ.get('POSTGRES_CONNECTION_STRING')
            test_conn_str = "postgresql://test:test@localhost:5432/testdb"
            os.environ['POSTGRES_CONNECTION_STRING'] = test_conn_str
            
            # Create new instance to test env variable
            test_db = DatabaseIntegration()
            env_conn_str = test_db.get_connection_string()
            
            assert env_conn_str == test_conn_str, "Should use environment variable"
            
            # Restore original environment
            if original_env:
                os.environ['POSTGRES_CONNECTION_STRING'] = original_env
            else:
                os.environ.pop('POSTGRES_CONNECTION_STRING', None)
            
            self._add_test_result("connection_string", True, "Connection string generation works correctly")
            
        except Exception as e:
            self._add_test_result("connection_string", False, f"Connection string test failed: {str(e)}")
    
    def _test_connection(self):
        """Test database connection"""
        logger.info("Testing database connection...")
        
        try:
            # Test connection
            result = self.db.test_connection()
            
            assert isinstance(result, dict), "Should return dictionary"
            assert 'success' in result, "Should have success field"
            assert 'message' in result, "Should have message field"
            
            if result['success']:
                assert 'response_time_ms' in result, "Should have response time"
                assert result['response_time_ms'] > 0, "Response time should be positive"
                
                if 'connection_method' in result:
                    valid_methods = ['psycopg2_pool', 'sqlalchemy', 'simulated']
                    assert result['connection_method'] in valid_methods, f"Invalid connection method: {result['connection_method']}"
            
            self._add_test_result("connection", result['success'], result['message'])
            
        except Exception as e:
            self._add_test_result("connection", False, f"Connection test failed: {str(e)}")
    
    def _test_schema_discovery(self):
        """Test database schema discovery"""
        logger.info("Testing schema discovery...")
        
        try:
            # Test schema discovery
            schema_info = self.db.discover_schema()
            
            assert isinstance(schema_info, dict), "Should return dictionary"
            
            if schema_info.get('success', True):  # Some implementations don't have success field
                # Test required fields
                required_fields = ['schemas', 'tables', 'total_tables', 'total_columns']
                for field in required_fields:
                    assert field in schema_info, f"Should have {field} field"
                
                # Test data types
                assert isinstance(schema_info['schemas'], list), "Schemas should be list"
                assert isinstance(schema_info['tables'], dict), "Tables should be dictionary"
                assert isinstance(schema_info['total_tables'], int), "Total tables should be integer"
                assert isinstance(schema_info['total_columns'], int), "Total columns should be integer"
                
                # Test that we have some data
                assert len(schema_info['schemas']) > 0, "Should have at least one schema"
                assert schema_info['total_tables'] > 0, "Should have at least one table"
                assert schema_info['total_columns'] > 0, "Should have at least one column"
                
                # Test table structure
                for schema_name, tables in schema_info['tables'].items():
                    assert isinstance(tables, list), f"Tables for {schema_name} should be list"
                    for table in tables:
                        assert 'name' in table, "Table should have name"
                        assert 'columns' in table, "Table should have columns"
                        assert isinstance(table['columns'], list), "Columns should be list"
                        
                        for column in table['columns']:
                            assert 'name' in column, "Column should have name"
                            assert 'type' in column, "Column should have type"
                
                # Test caching
                cached_schema = self.db.schema_cache
                assert cached_schema == schema_info, "Schema should be cached"
                
                self._add_test_result("schema_discovery", True, f"Discovered {schema_info['total_tables']} tables with {schema_info['total_columns']} columns")
            else:
                self._add_test_result("schema_discovery", False, schema_info.get('message', 'Schema discovery failed'))
            
        except Exception as e:
            self._add_test_result("schema_discovery", False, f"Schema discovery test failed: {str(e)}")
    
    def _test_sql_generation(self):
        """Test SQL generation from natural language"""
        logger.info("Testing SQL generation from natural language...")
        
        test_queries = [
            "Show me sales by region",
            "What are the monthly sales trends?",
            "Find the top selling products",
            "Analyze customer segments",
            "Show me product categories",
            "Give me a general overview"
        ]
        
        successful_generations = 0
        
        for query in test_queries:
            try:
                result = self.db.generate_sql_from_natural_language(query)
                
                assert isinstance(result, dict), "Should return dictionary"
                assert 'success' in result, "Should have success field"
                
                if result['success']:
                    assert 'sql_query' in result, "Should have SQL query"
                    assert 'explanation' in result, "Should have explanation"
                    assert 'complexity' in result, "Should have complexity assessment"
                    assert 'tables_used' in result, "Should have tables used"
                    
                    # Test SQL query format
                    sql_query = result['sql_query']
                    assert isinstance(sql_query, str), "SQL query should be string"
                    assert len(sql_query.strip()) > 0, "SQL query should not be empty"
                    assert 'select' in sql_query.lower(), "Should be SELECT query"
                    
                    # Test complexity assessment
                    valid_complexities = ['simple', 'moderate', 'complex', 'very_complex']
                    assert result['complexity'] in valid_complexities, f"Invalid complexity: {result['complexity']}"
                    
                    # Test tables used
                    assert isinstance(result['tables_used'], list), "Tables used should be list"
                    
                    successful_generations += 1
                    logger.info(f"âœ… Generated SQL for: '{query}' -> {result['explanation']}")
                else:
                    logger.warning(f"âŒ Failed to generate SQL for: '{query}' -> {result.get('message', 'Unknown error')}")
                
            except Exception as e:
                logger.error(f"âŒ SQL generation failed for '{query}': {str(e)}")
        
        success_rate = successful_generations / len(test_queries)
        self._add_test_result("sql_generation", success_rate > 0.5, f"Generated SQL for {successful_generations}/{len(test_queries)} queries (success rate: {success_rate:.1%})")
    
    def _test_query_execution(self):
        """Test SQL query execution"""
        logger.info("Testing SQL query execution...")
        
        test_queries = [
            "SELECT 1 as test_value",
            "SELECT 'hello' as greeting, 42 as number",
            """
            SELECT 
                region,
                SUM(total_amount) as total_sales,
                COUNT(*) as transaction_count
            FROM sales.transactions 
            GROUP BY region 
            ORDER BY total_sales DESC
            """,
            """
            SELECT 
                category,
                COUNT(*) as product_count,
                AVG(price) as avg_price
            FROM public.products
            GROUP BY category
            """
        ]
        
        successful_executions = 0
        
        for i, query in enumerate(test_queries):
            try:
                result = self.db.execute_query(query, limit=100)
                
                assert isinstance(result, dict), "Should return dictionary"
                assert 'success' in result, "Should have success field"
                
                if result['success']:
                    assert 'data' in result, "Should have data field"
                    assert 'columns' in result, "Should have columns field"
                    assert 'row_count' in result, "Should have row count"
                    assert 'execution_time_ms' in result, "Should have execution time"
                    
                    # Test data structure
                    assert isinstance(result['data'], list), "Data should be list"
                    assert isinstance(result['columns'], list), "Columns should be list"
                    assert isinstance(result['row_count'], int), "Row count should be integer"
                    assert isinstance(result['execution_time_ms'], (int, float)), "Execution time should be numeric"
                    
                    # Test data consistency
                    if result['data']:
                        assert len(result['data']) == result['row_count'], "Data length should match row count"
                        
                        # Test first row structure
                        first_row = result['data'][0]
                        assert isinstance(first_row, dict), "Row should be dictionary"
                        
                        # Test that columns match data keys
                        if result['columns']:
                            for col in result['columns']:
                                assert col in first_row, f"Column {col} should be in data"
                    
                    successful_executions += 1
                    logger.info(f"âœ… Executed query {i+1}: {result['row_count']} rows in {result['execution_time_ms']}ms")
                else:
                    logger.warning(f"âŒ Query {i+1} failed: {result.get('message', 'Unknown error')}")
                
            except Exception as e:
                logger.error(f"âŒ Query execution {i+1} failed: {str(e)}")
        
        success_rate = successful_executions / len(test_queries)
        self._add_test_result("query_execution", success_rate > 0.5, f"Executed {successful_executions}/{len(test_queries)} queries successfully (success rate: {success_rate:.1%})")
    
    def _test_performance_analysis(self):
        """Test query performance analysis"""
        logger.info("Testing query performance analysis...")
        
        test_queries = [
            "SELECT * FROM sales.transactions",  # Should suggest avoiding SELECT *
            "SELECT region, SUM(total_amount) FROM sales.transactions GROUP BY region",  # Moderate complexity
            """
            SELECT t.*, p.*, c.*
            FROM sales.transactions t
            JOIN public.products p ON t.product_id = p.product_id
            JOIN public.customers c ON t.customer_id = c.customer_id
            WHERE t.transaction_date >= '2024-01-01'
            """,  # Complex query
        ]
        
        successful_analyses = 0
        
        for i, query in enumerate(test_queries):
            try:
                # Test if method exists (it might not be implemented)
                if hasattr(self.db, 'analyze_query_performance'):
                    result = self.db.analyze_query_performance(query)
                    
                    assert isinstance(result, dict), "Should return dictionary"
                    
                    if 'error' not in result:
                        # Test required fields
                        expected_fields = ['complexity', 'estimated_rows', 'tables_used']
                        for field in expected_fields:
                            assert field in result, f"Should have {field} field"
                        
                        # Test complexity
                        valid_complexities = ['simple', 'moderate', 'complex', 'very_complex']
                        assert result['complexity'] in valid_complexities, f"Invalid complexity: {result['complexity']}"
                        
                        # Test estimated rows
                        assert isinstance(result['estimated_rows'], int), "Estimated rows should be integer"
                        assert result['estimated_rows'] > 0, "Estimated rows should be positive"
                        
                        # Test tables used
                        assert isinstance(result['tables_used'], list), "Tables used should be list"
                        
                        successful_analyses += 1
                        logger.info(f"âœ… Analyzed query {i+1}: {result['complexity']} complexity, ~{result['estimated_rows']} rows")
                    else:
                        logger.warning(f"âŒ Performance analysis {i+1} failed: {result.get('message', 'Unknown error')}")
                else:
                    logger.info("Performance analysis method not implemented - skipping")
                    successful_analyses = len(test_queries)  # Consider as success
                    break
                
            except Exception as e:
                logger.error(f"âŒ Performance analysis {i+1} failed: {str(e)}")
        
        success_rate = successful_analyses / len(test_queries)
        self._add_test_result("performance_analysis", success_rate >= 0.5, f"Analyzed {successful_analyses}/{len(test_queries)} queries successfully")
    
    def _test_error_handling(self):
        """Test error handling"""
        logger.info("Testing error handling...")
        
        error_test_cases = [
            {
                'name': 'Invalid SQL syntax',
                'query': 'SELCT * FORM invalid_table',
                'should_fail': True
            },
            {
                'name': 'Non-existent table',
                'query': 'SELECT * FROM non_existent_table',
                'should_fail': True
            },
            {
                'name': 'Empty query',
                'query': '',
                'should_fail': True
            },
            {
                'name': 'SQL injection attempt',
                'query': "SELECT * FROM users WHERE id = 1; DROP TABLE users; --",
                'should_fail': True
            }
        ]
        
        successful_error_handling = 0
        
        for test_case in error_test_cases:
            try:
                result = self.db.execute_query(test_case['query'])
                
                if test_case['should_fail']:
                    if not result.get('success', True):
                        successful_error_handling += 1
                        logger.info(f"âœ… Correctly handled error: {test_case['name']}")
                    else:
                        logger.warning(f"âŒ Should have failed but didn't: {test_case['name']}")
                else:
                    if result.get('success', False):
                        successful_error_handling += 1
                        logger.info(f"âœ… Correctly executed: {test_case['name']}")
                    else:
                        logger.warning(f"âŒ Should have succeeded but failed: {test_case['name']}")
                
            except Exception as e:
                if test_case['should_fail']:
                    successful_error_handling += 1
                    logger.info(f"âœ… Correctly raised exception for: {test_case['name']}")
                else:
                    logger.error(f"âŒ Unexpected exception for {test_case['name']}: {str(e)}")
        
        success_rate = successful_error_handling / len(error_test_cases)
        self._add_test_result("error_handling", success_rate >= 0.75, f"Handled {successful_error_handling}/{len(error_test_cases)} error cases correctly")
    
    def _test_cleanup(self):
        """Test cleanup operations"""
        logger.info("Testing cleanup operations...")
        
        try:
            # Test connection cleanup
            if hasattr(self.db, 'close_connections'):
                self.db.close_connections()
                logger.info("âœ… Connection cleanup completed")
            
            # Test cache clearing
            original_cache_size = len(self.db.schema_cache)
            self.db.schema_cache.clear()
            assert len(self.db.schema_cache) == 0, "Cache should be empty after clearing"
            
            self._add_test_result("cleanup", True, "Cleanup operations completed successfully")
            
        except Exception as e:
            self._add_test_result("cleanup", False, f"Cleanup failed: {str(e)}")
    
    def _add_test_result(self, test_name: str, success: bool, message: str):
        """Add a test result"""
        self.test_results.append({
            'test_name': test_name,
            'success': success,
            'message': message,
            'timestamp': time.time()
        })
        
        status = "âœ… PASS" if success else "âŒ FAIL"
        logger.info(f"{status}: {test_name} - {message}")
    
    def _generate_test_summary(self) -> Dict[str, Any]:
        """Generate comprehensive test summary"""
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results if result['success'])
        failed_tests = total_tests - passed_tests
        success_rate = passed_tests / total_tests if total_tests > 0 else 0
        
        execution_time = time.time() - self.start_time
        
        summary = {
            'success': success_rate >= 0.7,  # 70% pass rate required
            'total_tests': total_tests,
            'passed_tests': passed_tests,
            'failed_tests': failed_tests,
            'success_rate': round(success_rate * 100, 1),
            'execution_time_seconds': round(execution_time, 2),
            'test_results': self.test_results,
            'recommendations': self._generate_recommendations(),
            'summary_message': f"Database Integration Test Suite: {passed_tests}/{total_tests} tests passed ({success_rate:.1%} success rate)"
        }
        
        return summary
    
    def _generate_recommendations(self) -> List[str]:
        """Generate recommendations based on test results"""
        recommendations = []
        
        failed_tests = [result for result in self.test_results if not result['success']]
        
        if any('connection' in test['test_name'] for test in failed_tests):
            recommendations.append("Consider installing psycopg2 or SQLAlchemy for real database connectivity")
        
        if any('sql_generation' in test['test_name'] for test in failed_tests):
            recommendations.append("Improve natural language to SQL conversion logic")
        
        if any('query_execution' in test['test_name'] for test in failed_tests):
            recommendations.append("Review query execution error handling and data formatting")
        
        if any('schema_discovery' in test['test_name'] for test in failed_tests):
            recommendations.append("Verify database schema discovery queries and permissions")
        
        if len(failed_tests) == 0:
            recommendations.append("All tests passed! Database integration is working correctly")
        elif len(failed_tests) < 3:
            recommendations.append("Most tests passed - minor issues to address")
        else:
            recommendations.append("Multiple test failures - review database integration implementation")
        
        return recommendations

def main():
    """Main test execution function"""
    print("ðŸš€ Starting Database Integration Test Suite")
    print("=" * 60)
    
    tester = DatabaseIntegrationTester()
    results = tester.run_all_tests()
    
    print("\n" + "=" * 60)
    print("ðŸ“Š TEST SUMMARY")
    print("=" * 60)
    
    print(f"Total Tests: {results['total_tests']}")
    print(f"Passed: {results['passed_tests']} âœ…")
    print(f"Failed: {results['failed_tests']} âŒ")
    print(f"Success Rate: {results['success_rate']}%")
    print(f"Execution Time: {results['execution_time_seconds']}s")
    
    if results['recommendations']:
        print("\nðŸ“‹ RECOMMENDATIONS:")
        for i, rec in enumerate(results['recommendations'], 1):
            print(f"{i}. {rec}")
    
    print(f"\nðŸŽ¯ OVERALL RESULT: {'âœ… PASS' if results['success'] else 'âŒ FAIL'}")
    print(f"Message: {results['summary_message']}")
    
    # Save results to file
    results_file = 'database_integration_test_results.json'
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\nðŸ’¾ Detailed results saved to: {results_file}")
    
    return results['success']

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)